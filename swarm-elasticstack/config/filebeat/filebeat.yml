#=========================== Filebeat inputs =============================

filebeat.inputs:
  - type: docker
    combine_partial: true
    # Json key name, which value contains a sub JSON document produced by our application Console Appender
    containers:
      path: "/usr/share/dockerlogs/data"
      stream: "stdout"
      ids:
        - "*"
    exclude_files: ['\.gz$']

#============================= Filebeat modules ===============================

filebeat.config.modules:
  # Glob pattern for configuration loading
  path: ${path.config}/modules.d/*.yml

  # Set to true to enable config reloading
  reload.enabled: false

#============================== Kibana =====================================

# Starting with Beats version 6.0.0, the dashboards are loaded via the Kibana API.
# Kibana
setup:
  kibana:
    host: "kibana:5601"
    username: "kibana"
    password: "changeme"
    #protocol: 'http'
    #path: '/kibana'
    # dashboards.enabled: true

#================================ Outputs =====================================

# Configure what output to use when sending the data collected by the beat.

#-------------------------- Elasticsearch output ------------------------------
output.elasticsearch:
  # Array of hosts to connect to.
  hosts: "elasticsearch:9200"
  #protocol: http
  template:
    name: "filebeat"
    #    path: "my_fields.yml"
    path: "fields.yml"
    #    overwrite: true
    overwrite: false

  #----------------------------- Logstash output --------------------------------
  #output.logstash:
  # The Logstash hosts
  # hosts: ["localhost:5044"]

  # Optional SSL. By default is off.
  # List of root certificates for HTTPS server verifications
  #ssl.certificate_authorities: ["/etc/pki/root/ca.pem"]

  # Certificate for SSL client authentication
  #ssl.certificate: "/etc/pki/client/cert.pem"

  # Client Certificate Key
  #ssl.key: "/etc/pki/client/cert.key"


#============================== Processors ===================================

processors:
  # decode the log field (sub JSON document) if JSONencoded, then maps it's fields to elasticsearch fields
  - decode_json_fields:
      fields: ["log","message"]
      target: ""
      # overwrite existing target elasticsearch fields while decoding json fields
      overwrite_keys: true
  #  - add_docker_metadata: ~
  - add_docker_metadata:
      host: "unix:///var/run/docker.sock"

#================================ Logging =====================================

# Write Filebeat own logs only to file to avoid catching them with itself in docker log files
logging.level: error
logging.to_files: true
logging.to_syslog: false
logging.metrics.enabled: false
logging.files:
  path: /var/log/filebeat
  name: filebeat
  keepfiles: 7
  permissions: 0644

#============================== Dashboards =====================================
# These settings control loading the sample dashboards to the Kibana index. Loading
# the dashboards are disabled by default and can be enabled either by setting the
# options here, or by using the `-setup` CLI flag or the `setup` command.
setup.dashboards.enabled: true

#============================== Xpack Monitoring ===============================
# filebeat can export internal metrics to a central Elasticsearch monitoring
# cluster.  This requires xpack monitoring to be enabled in Elasticsearch.  The
# reporting is disabled by default.

# Set to true to enable the monitoring reporter.
#xpack.monitoring.enabled: true
xpack.monitoring.enabled: false


# Uncomment to send the metrics to Elasticsearch. Most settings from the
# Elasticsearch output are accepted here as well. Any setting that is not set is
# automatically inherited from the Elasticsearch output configuration, so if you
# have the Elasticsearch output configured, you can simply uncomment the
# following line.
xpack.monitoring.elasticsearch:
